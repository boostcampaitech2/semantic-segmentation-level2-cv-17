{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmcv\n",
    "from mmcv import Config\n",
    "from mmseg.datasets import build_dataloader, build_dataset\n",
    "from mmseg.models import build_segmentor\n",
    "from mmseg.apis import single_gpu_test\n",
    "from mmcv.runner import load_checkpoint\n",
    "import os\n",
    "from mmcv.parallel import MMDataParallel\n",
    "import pandas as pd\n",
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import cv2\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config file 들고오기\n",
    "config = 'upernet_swin_large_patch4_window12_512x512_80k_coco_pretrain_384x384_22K'\n",
    "cfg = Config.fromfile(f'./configs/swin/{config}.py')\n",
    "\n",
    "root = '../input/data/'\n",
    "\n",
    "epoch = 'best_mIoU_iter_58000'\n",
    "\n",
    "# dataset config 수정\n",
    "# cfg.data.test.classes = classes\n",
    "# cfg.data.test.img_prefix = root\n",
    "# cfg.data.test.ann_file = root + 'test.json'\n",
    "cfg.data.test.data_root = root\n",
    "cfg.data.test.img_dir = 'test/'\n",
    "# cfg.data.val.ann_dir = 'test/'\n",
    "# cfg.data.test.pipeline[1]['img_scale'] = (512,512) # Resized\n",
    "cfg.data.test.test_mode = True\n",
    "\n",
    "cfg.data.samples_per_gpu = 4\n",
    "\n",
    "cfg.seed=1995\n",
    "cfg.gpu_ids = [1]\n",
    "cfg.work_dir = f'./work_dirs/{config}'\n",
    "\n",
    "# cfg.model.roi_head.bbox_head.num_classes = 10\n",
    "# cfg.model.bbox_head.num_classes = 10\n",
    "# for head in cfg.model.roi_head.bbox_head:\n",
    "#     head.num_classes = 10\n",
    "\n",
    "# cfg.optimizer_config.grad_clip = dict(max_norm=35, norm_type=2)\n",
    "cfg.model.train_cfg = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-02 20:41:14,373 - mmseg - INFO - Loaded 819 images\n"
     ]
    }
   ],
   "source": [
    "# build dataset & dataloader\n",
    "dataset = build_dataset(cfg.data.test)\n",
    "data_loader = build_dataloader(\n",
    "        dataset,\n",
    "        samples_per_gpu=1,\n",
    "        workers_per_gpu=cfg.data.workers_per_gpu,\n",
    "        dist=False,\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/ml/segmentation/mmsegmentation/mmseg/models/backbones/swin.py:556: UserWarning: DeprecationWarning: pretrained is deprecated, please use \"init_cfg\" instead\n",
      "  warnings.warn('DeprecationWarning: pretrained is deprecated, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use load_from_local loader\n"
     ]
    }
   ],
   "source": [
    "# checkpoint path\n",
    "checkpoint_path = os.path.join(cfg.work_dir, f'{epoch}.pth')\n",
    "\n",
    "model = build_segmentor(cfg.model, test_cfg=cfg.get('test_cfg')) # build detector\n",
    "checkpoint = load_checkpoint(model, checkpoint_path, map_location='cpu') # ckpt load\n",
    "\n",
    "model.CLASSES = dataset.CLASSES\n",
    "model = MMDataParallel(model.cuda(), device_ids=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 819/819, 0.4 task/s, elapsed: 2262s, ETA:     0s"
     ]
    }
   ],
   "source": [
    "output = single_gpu_test(model, data_loader) # output 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(idx, coco):\n",
    "    size = 256\n",
    "    transform = A.Compose([A.Resize(size, size)])\n",
    "\n",
    "    file_name_list = []\n",
    "    preds_array = np.empty((0, size*size), dtype=np.long)\n",
    "\n",
    "    image_id = coco.getImgIds(imgIds=idx)\n",
    "    image_infos = coco.loadImgs(image_id)[0]\n",
    "    file_name = image_infos['file_name']\n",
    "\n",
    "    outs = output[idx] # mask\n",
    "    img = cv2.imread('/opt/ml/segmentation/input/data/'+file_name) # image\n",
    "\n",
    "    transformed = transform(image=img, mask=outs, interpolation=2)\n",
    "    mask = transformed['mask'].reshape((256 * 256)).astype(int)\n",
    "\n",
    "    file_name_list.append(file_name)\n",
    "    preds_array = np.vstack((preds_array, mask))\n",
    "    return file_name_list, preds_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/segmentation/lib/python3.7/site-packages/ipykernel_launcher.py:6: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# sample_submisson.csv 열기\n",
    "submission = pd.read_csv('/opt/ml/segmentation/baseline_code/submission/sample_submission.csv', index_col=None)\n",
    "coco = COCO('/opt/ml/segmentation/input/data/test.json')\n",
    "\n",
    "# test set에 대한 prediction\n",
    "for idx in range(len(output)):\n",
    "    file_names, preds = test(idx, coco)\n",
    "\n",
    "    # PredictionString 대입\n",
    "    for file_name, string in zip(file_names, preds):\n",
    "        submission = submission.append({\"image_id\" : file_name, \"PredictionString\" : ' '.join(str(e) for e in string.tolist())},\n",
    "                                        ignore_index=True)\n",
    "\n",
    "# submission.csv로 저장\n",
    "submission.to_csv(cfg.work_dir + \"/submission/submission_42k.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d36e052b391be8c28b05838ade06426769a29575d5fe21a7bc69c7dec0c04c06"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('segmentation': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
